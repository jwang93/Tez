2015-02-28 01:26:06,958 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.37.127
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-02-28 01:26:06,969 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-02-28 01:26:07,490 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-02-28 01:26:07,657 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-02-28 01:26:07,954 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-02-28 01:26:07,954 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-02-28 01:26:08,366 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 17973@jays-MacBook-Pro-2.local
2015-02-28 01:26:08,399 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-02-28 01:26:08,408 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-02-28 01:26:08,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-02-28 01:26:08,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-02-28 01:26:08,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-02-28 01:26:08,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Feb 28 01:26:08
2015-02-28 01:26:08,463 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-02-28 01:26:08,464 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 01:26:08,470 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-02-28 01:26:08,471 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-02-28 01:26:08,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-02-28 01:26:08,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-02-28 01:26:08,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-02-28 01:26:08,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-02-28 01:26:08,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-02-28 01:26:08,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-02-28 01:26:08,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-02-28 01:26:08,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-02-28 01:26:08,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-02-28 01:26:08,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-02-28 01:26:08,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-02-28 01:26:08,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-02-28 01:26:08,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-02-28 01:26:08,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-02-28 01:26:08,674 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-02-28 01:26:08,674 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 01:26:08,674 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-02-28 01:26:08,674 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-02-28 01:26:08,696 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-02-28 01:26:08,703 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-02-28 01:26:08,704 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 01:26:08,704 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-02-28 01:26:08,704 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-02-28 01:26:08,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-02-28 01:26:08,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-02-28 01:26:08,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-02-28 01:26:08,709 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-02-28 01:26:08,709 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-02-28 01:26:08,709 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-02-28 01:26:08,724 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-02-28 01:26:08,781 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-02-28 01:26:08,786 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-02-28 01:26:08,798 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-02-28 01:26:08,800 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-02-28 01:26:08,800 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-02-28 01:26:08,800 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-02-28 01:26:08,842 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-02-28 01:26:08,842 INFO org.mortbay.log: jetty-6.1.26
2015-02-28 01:26:09,080 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-02-28 01:26:09,080 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-02-28 01:26:09,081 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-02-28 01:26:09,081 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-02-28 01:27:09,337 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-02-28 01:27:09,815 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-02-28 01:27:09,895 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-02-28 01:27:10,327 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2015-02-28 01:27:10,327 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 354 bytes.
2015-02-28 01:27:10,332 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=4&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-02-28 01:27:10,335 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-02-28 01:27:10,336 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000004_0000001425104830332 size 0 bytes.
2015-02-28 01:27:10,370 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-02-28 01:27:10,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-02-28 01:27:10,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000000
2015-02-28 01:27:10,400 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-02-28 01:27:10,405 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-02-28 01:27:10,409 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000004 expecting start txid #1
2015-02-28 01:27:10,409 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000004
2015-02-28 01:27:10,442 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000004 of size 194 edits # 4 loaded in 0 seconds
2015-02-28 01:27:10,494 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-jaywang/dfs/namesecondary
2015-02-28 01:27:10,607 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4 to namenode at http://localhost:50070 in 0.107 seconds
2015-02-28 01:27:10,607 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 493
2015-02-28 01:38:11,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 01:38:12,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 01:38:13,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 01:38:14,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 01:38:15,531 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-02-28 01:38:15,532 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.37.127
************************************************************/
2015-02-28 01:43:48,928 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.37.127
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-02-28 01:43:48,942 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-02-28 01:43:49,465 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-02-28 01:43:49,634 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-02-28 01:43:49,905 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-02-28 01:43:49,905 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-02-28 01:43:50,174 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 19450@jays-MacBook-Pro-2.local
2015-02-28 01:43:50,245 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-02-28 01:43:50,252 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-02-28 01:43:50,296 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-02-28 01:43:50,296 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-02-28 01:43:50,297 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-02-28 01:43:50,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Feb 28 01:43:50
2015-02-28 01:43:50,300 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-02-28 01:43:50,300 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 01:43:50,304 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-02-28 01:43:50,304 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-02-28 01:43:50,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-02-28 01:43:50,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-02-28 01:43:50,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-02-28 01:43:50,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-02-28 01:43:50,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-02-28 01:43:50,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-02-28 01:43:50,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-02-28 01:43:50,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-02-28 01:43:50,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-02-28 01:43:50,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-02-28 01:43:50,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-02-28 01:43:50,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-02-28 01:43:50,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-02-28 01:43:50,321 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-02-28 01:43:50,522 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-02-28 01:43:50,522 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 01:43:50,522 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-02-28 01:43:50,522 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-02-28 01:43:50,523 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-02-28 01:43:50,531 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-02-28 01:43:50,531 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 01:43:50,532 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-02-28 01:43:50,532 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-02-28 01:43:50,533 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-02-28 01:43:50,533 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-02-28 01:43:50,533 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-02-28 01:43:50,535 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-02-28 01:43:50,536 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-02-28 01:43:50,536 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-02-28 01:43:50,548 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-02-28 01:43:50,604 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-02-28 01:43:50,608 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-02-28 01:43:50,621 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-02-28 01:43:50,623 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-02-28 01:43:50,623 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-02-28 01:43:50,623 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-02-28 01:43:50,657 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-02-28 01:43:50,657 INFO org.mortbay.log: jetty-6.1.26
2015-02-28 01:43:50,889 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-02-28 01:43:50,889 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-02-28 01:43:50,890 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-02-28 01:43:50,890 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-02-28 01:44:51,088 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-02-28 01:44:51,389 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=4&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-02-28 01:44:51,420 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-02-28 01:44:51,785 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-02-28 01:44:51,786 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000004 size 493 bytes.
2015-02-28 01:44:51,794 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=5&endTxId=180&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-02-28 01:44:51,809 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 85333.33 KB/s
2015-02-28 01:44:51,809 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000005-0000000000000000180_0000001425105891794 size 0 bytes.
2015-02-28 01:44:51,810 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=181&endTxId=182&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-02-28 01:44:51,814 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-02-28 01:44:51,814 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000181-0000000000000000182_0000001425105891810 size 0 bytes.
2015-02-28 01:44:51,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 3 INodes.
2015-02-28 01:44:51,891 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-02-28 01:44:51,891 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000004
2015-02-28 01:44:51,891 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-02-28 01:44:51,897 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-02-28 01:44:51,901 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000005-0000000000000000180 expecting start txid #5
2015-02-28 01:44:51,902 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000005-0000000000000000180
2015-02-28 01:44:51,982 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000005-0000000000000000180 of size 1048576 edits # 176 loaded in 0 seconds
2015-02-28 01:44:51,982 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000181-0000000000000000182 expecting start txid #181
2015-02-28 01:44:51,982 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000181-0000000000000000182
2015-02-28 01:44:51,982 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000181-0000000000000000182 of size 42 edits # 2 loaded in 0 seconds
2015-02-28 01:44:52,064 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4
2015-02-28 01:44:52,064 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2015-02-28 01:44:52,094 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 182 to namenode at http://localhost:50070 in 0.021 seconds
2015-02-28 01:44:52,095 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2785
2015-02-28 01:53:53,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 01:53:53,844 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-02-28 01:53:53,854 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.37.127
************************************************************/
2015-02-28 02:20:39,745 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.37.127
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-02-28 02:20:39,757 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-02-28 02:20:40,297 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-02-28 02:20:40,465 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-02-28 02:20:40,773 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-02-28 02:20:40,773 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-02-28 02:20:41,194 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 21486@jays-MacBook-Pro-2.local
2015-02-28 02:20:41,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-02-28 02:20:41,332 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-02-28 02:20:41,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-02-28 02:20:41,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-02-28 02:20:41,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-02-28 02:20:41,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Feb 28 02:20:41
2015-02-28 02:20:41,384 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-02-28 02:20:41,384 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 02:20:41,387 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-02-28 02:20:41,387 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-02-28 02:20:41,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-02-28 02:20:41,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-02-28 02:20:41,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-02-28 02:20:41,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-02-28 02:20:41,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-02-28 02:20:41,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-02-28 02:20:41,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-02-28 02:20:41,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-02-28 02:20:41,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-02-28 02:20:41,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-02-28 02:20:41,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-02-28 02:20:41,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-02-28 02:20:41,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-02-28 02:20:41,406 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-02-28 02:20:41,607 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-02-28 02:20:41,607 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 02:20:41,607 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-02-28 02:20:41,607 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-02-28 02:20:41,608 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-02-28 02:20:41,616 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-02-28 02:20:41,616 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 02:20:41,616 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-02-28 02:20:41,616 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-02-28 02:20:41,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-02-28 02:20:41,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-02-28 02:20:41,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-02-28 02:20:41,620 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-02-28 02:20:41,620 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-02-28 02:20:41,620 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-02-28 02:20:41,666 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-02-28 02:20:41,721 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-02-28 02:20:41,725 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-02-28 02:20:41,739 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-02-28 02:20:41,742 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-02-28 02:20:41,742 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-02-28 02:20:41,742 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-02-28 02:20:41,784 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-02-28 02:20:41,784 INFO org.mortbay.log: jetty-6.1.26
2015-02-28 02:20:42,011 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-02-28 02:20:42,011 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-02-28 02:20:42,012 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-02-28 02:20:42,012 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-02-28 02:21:42,274 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-02-28 02:21:42,736 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=182&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-02-28 02:21:42,782 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-02-28 02:21:43,115 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 285.71 KB/s
2015-02-28 02:21:43,115 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000182 size 2785 bytes.
2015-02-28 02:21:43,123 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=183&endTxId=414&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-02-28 02:21:43,137 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 93090.91 KB/s
2015-02-28 02:21:43,138 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000183-0000000000000000414_0000001425108103123 size 0 bytes.
2015-02-28 02:21:43,138 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=415&endTxId=416&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-02-28 02:21:43,141 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-02-28 02:21:43,141 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000415-0000000000000000416_0000001425108103138 size 0 bytes.
2015-02-28 02:21:43,176 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 33 INodes.
2015-02-28 02:21:43,219 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-02-28 02:21:43,219 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 182 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000182
2015-02-28 02:21:43,219 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-02-28 02:21:43,235 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-02-28 02:21:43,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000183-0000000000000000414 expecting start txid #183
2015-02-28 02:21:43,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000183-0000000000000000414
2015-02-28 02:21:43,343 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000183-0000000000000000414 of size 1048576 edits # 232 loaded in 0 seconds
2015-02-28 02:21:43,343 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000415-0000000000000000416 expecting start txid #415
2015-02-28 02:21:43,343 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000415-0000000000000000416
2015-02-28 02:21:43,343 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000415-0000000000000000416 of size 42 edits # 2 loaded in 0 seconds
2015-02-28 02:21:43,419 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 182
2015-02-28 02:21:43,420 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000004, cpktTxId=0000000000000000004)
2015-02-28 02:21:43,465 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 416 to namenode at http://localhost:50070 in 0.035 seconds
2015-02-28 02:21:43,465 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4364
2015-02-28 02:25:30,764 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-02-28 02:25:30,765 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.37.127
************************************************************/
2015-02-28 15:26:08,833 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.54.20
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-02-28 15:26:08,886 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-02-28 15:26:09,443 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-02-28 15:26:09,668 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-02-28 15:26:10,159 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-02-28 15:26:10,159 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-02-28 15:26:10,431 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 24505@jays-MacBook-Pro-2.local
2015-02-28 15:26:10,560 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-02-28 15:26:10,566 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-02-28 15:26:10,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-02-28 15:26:10,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-02-28 15:26:10,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-02-28 15:26:10,610 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Feb 28 15:26:10
2015-02-28 15:26:10,612 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-02-28 15:26:10,612 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 15:26:10,616 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-02-28 15:26:10,616 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-02-28 15:26:10,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-02-28 15:26:10,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-02-28 15:26:10,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-02-28 15:26:10,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-02-28 15:26:10,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-02-28 15:26:10,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-02-28 15:26:10,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-02-28 15:26:10,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-02-28 15:26:10,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-02-28 15:26:10,631 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-02-28 15:26:10,631 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-02-28 15:26:10,631 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-02-28 15:26:10,631 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-02-28 15:26:10,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-02-28 15:26:10,834 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-02-28 15:26:10,834 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 15:26:10,835 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-02-28 15:26:10,835 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-02-28 15:26:10,835 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-02-28 15:26:10,844 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-02-28 15:26:10,844 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-02-28 15:26:10,844 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-02-28 15:26:10,844 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-02-28 15:26:10,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-02-28 15:26:10,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-02-28 15:26:10,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-02-28 15:26:10,848 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-02-28 15:26:10,848 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-02-28 15:26:10,849 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-02-28 15:26:10,861 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-02-28 15:26:10,922 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-02-28 15:26:10,929 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-02-28 15:26:10,940 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-02-28 15:26:10,942 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-02-28 15:26:10,942 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-02-28 15:26:10,943 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-02-28 15:26:10,977 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-02-28 15:26:10,978 INFO org.mortbay.log: jetty-6.1.26
2015-02-28 15:26:11,228 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-02-28 15:26:11,228 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-02-28 15:26:11,229 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-02-28 15:26:11,229 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-02-28 15:27:11,480 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-02-28 15:27:11,955 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=510&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-02-28 15:27:12,008 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-02-28 15:27:12,428 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 833.33 KB/s
2015-02-28 15:27:12,428 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000510 size 5480 bytes.
2015-02-28 15:27:12,434 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=511&endTxId=514&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-02-28 15:27:12,437 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-02-28 15:27:12,437 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000511-0000000000000000514_0000001425155232433 size 0 bytes.
2015-02-28 15:27:12,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 71 INodes.
2015-02-28 15:27:12,516 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-02-28 15:27:12,516 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 510 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000510
2015-02-28 15:27:12,517 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-02-28 15:27:12,522 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-02-28 15:27:12,529 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000511-0000000000000000514 expecting start txid #511
2015-02-28 15:27:12,530 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000511-0000000000000000514
2015-02-28 15:27:12,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000511-0000000000000000514 of size 302 edits # 4 loaded in 0 seconds
2015-02-28 15:27:12,623 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 510
2015-02-28 15:27:12,623 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000182, cpktTxId=0000000000000000182)
2015-02-28 15:27:12,624 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000416, cpktTxId=0000000000000000416)
2015-02-28 15:27:12,753 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 514 to namenode at http://localhost:50070 in 0.116 seconds
2015-02-28 15:27:12,753 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5647
2015-02-28 15:46:14,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 15:46:15,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 15:46:16,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 15:46:17,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 15:46:18,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 15:46:19,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 15:46:20,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 15:46:21,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 15:46:22,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 15:46:23,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-02-28 15:46:23,150 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.54.20 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 17 more
2015-02-28 15:46:23,445 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-02-28 15:46:23,446 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.54.20
************************************************************/
2015-03-02 23:02:58,449 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.37.127
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-02 23:02:58,653 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-02 23:02:59,427 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-02 23:02:59,631 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-02 23:03:00,505 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-02 23:03:00,505 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-02 23:03:04,786 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 55520@jays-MacBook-Pro-2.local
2015-03-02 23:03:05,270 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-02 23:03:05,277 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-02 23:03:05,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-02 23:03:05,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-02 23:03:05,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-02 23:03:05,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 02 23:03:05
2015-03-02 23:03:05,365 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-02 23:03:05,365 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-02 23:03:05,369 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-02 23:03:05,369 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-02 23:03:05,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-02 23:03:05,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-02 23:03:05,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-02 23:03:05,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-02 23:03:05,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-02 23:03:05,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-02 23:03:05,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-02 23:03:05,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-02 23:03:05,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-02 23:03:05,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-02 23:03:05,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-02 23:03:05,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-02 23:03:05,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-02 23:03:05,388 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-02 23:03:05,952 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-02 23:03:05,952 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-02 23:03:05,953 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-02 23:03:05,953 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-02 23:03:05,957 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-02 23:03:06,424 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-02 23:03:06,440 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-02 23:03:06,441 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-02 23:03:06,441 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-02 23:03:06,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-02 23:03:06,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-02 23:03:06,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-02 23:03:06,447 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-02 23:03:06,447 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-02 23:03:06,447 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-02 23:03:06,669 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-02 23:03:06,746 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-02 23:03:06,750 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-02 23:03:06,790 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-02 23:03:06,793 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-02 23:03:06,793 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-02 23:03:06,793 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-02 23:03:06,829 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-02 23:03:06,829 INFO org.mortbay.log: jetty-6.1.26
2015-03-02 23:03:07,312 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-02 23:03:07,313 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-02 23:03:07,313 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-02 23:03:07,314 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-02 23:04:08,282 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-02 23:04:09,449 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=599&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-02 23:04:09,550 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-02 23:04:10,193 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 238.10 KB/s
2015-03-02 23:04:10,193 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000599 size 5405 bytes.
2015-03-02 23:04:10,198 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=600&endTxId=601&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-02 23:04:10,322 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.12s at 0.00 KB/s
2015-03-02 23:04:10,322 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000600-0000000000000000601_0000001425355450198 size 0 bytes.
2015-03-02 23:04:10,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 70 INodes.
2015-03-02 23:04:10,407 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-02 23:04:10,407 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 599 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000599
2015-03-02 23:04:10,407 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-02 23:04:10,436 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-02 23:04:10,442 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000600-0000000000000000601 expecting start txid #600
2015-03-02 23:04:10,442 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000600-0000000000000000601
2015-03-02 23:04:10,468 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000600-0000000000000000601 of size 42 edits # 2 loaded in 0 seconds
2015-03-02 23:04:10,839 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 599
2015-03-02 23:04:10,840 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000510, cpktTxId=0000000000000000510)
2015-03-02 23:04:10,841 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000514, cpktTxId=0000000000000000514)
2015-03-02 23:04:11,038 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 601 to namenode at http://localhost:50070 in 0.148 seconds
2015-03-02 23:04:11,039 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5405
2015-03-03 00:04:11,992 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-03-03 00:04:12,065 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=602&endTxId=611&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 00:04:12,096 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-03-03 00:04:12,096 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000602-0000000000000000611_0000001425359052064 size 0 bytes.
2015-03-03 00:04:12,098 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-03 00:04:12,098 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000602-0000000000000000611 expecting start txid #602
2015-03-03 00:04:12,098 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000602-0000000000000000611
2015-03-03 00:04:12,122 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000602-0000000000000000611 of size 680 edits # 10 loaded in 0 seconds
2015-03-03 00:04:12,140 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 601
2015-03-03 00:04:12,140 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000599, cpktTxId=0000000000000000599)
2015-03-03 00:04:12,160 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 611 to namenode at http://localhost:50070 in 0.014 seconds
2015-03-03 00:04:12,160 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5529
2015-03-03 01:04:13,721 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-03-03 01:04:13,810 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=612&endTxId=622&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 01:04:13,815 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-03-03 01:04:13,815 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000612-0000000000000000622_0000001425362653809 size 0 bytes.
2015-03-03 01:04:13,815 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-03 01:04:13,815 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000612-0000000000000000622 expecting start txid #612
2015-03-03 01:04:13,815 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000612-0000000000000000622
2015-03-03 01:04:13,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000612-0000000000000000622 of size 1001 edits # 11 loaded in 0 seconds
2015-03-03 01:04:13,880 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 611
2015-03-03 01:04:13,880 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000601, cpktTxId=0000000000000000601)
2015-03-03 01:04:13,894 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 622 to namenode at http://localhost:50070 in 0.011 seconds
2015-03-03 01:04:13,895 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5614
2015-03-03 01:13:55,233 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-03 01:13:55,234 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.37.127
************************************************************/
2015-03-03 01:14:16,663 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.37.127
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-03 01:14:16,674 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-03 01:14:17,210 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-03 01:14:17,389 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-03 01:14:17,733 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-03 01:14:17,733 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-03 01:14:18,017 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 63714@jays-MacBook-Pro-2.local
2015-03-03 01:14:18,127 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-03 01:14:18,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-03 01:14:18,182 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-03 01:14:18,183 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-03 01:14:18,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-03 01:14:18,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 03 01:14:18
2015-03-03 01:14:18,188 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-03 01:14:18,188 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-03 01:14:18,192 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-03 01:14:18,192 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-03 01:14:18,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-03 01:14:18,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-03 01:14:18,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-03 01:14:18,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-03 01:14:18,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-03 01:14:18,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-03 01:14:18,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-03 01:14:18,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-03 01:14:18,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-03 01:14:18,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-03 01:14:18,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-03 01:14:18,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-03 01:14:18,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-03 01:14:18,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-03 01:14:18,418 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-03 01:14:18,418 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-03 01:14:18,419 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-03 01:14:18,419 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-03 01:14:18,419 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-03 01:14:18,427 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-03 01:14:18,428 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-03 01:14:18,428 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-03 01:14:18,428 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-03 01:14:18,429 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-03 01:14:18,429 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-03 01:14:18,429 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-03 01:14:18,432 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-03 01:14:18,432 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-03 01:14:18,432 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-03 01:14:18,445 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-03 01:14:18,501 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-03 01:14:18,505 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-03 01:14:18,519 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-03 01:14:18,522 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-03 01:14:18,522 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-03 01:14:18,522 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-03 01:14:18,554 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-03 01:14:18,554 INFO org.mortbay.log: jetty-6.1.26
2015-03-03 01:14:18,822 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-03 01:14:18,822 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-03 01:14:18,823 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-03 01:14:18,823 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-03 01:15:18,977 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-03 01:15:19,355 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=622&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 01:15:19,390 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-03 01:15:19,805 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 833.33 KB/s
2015-03-03 01:15:19,805 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000622 size 5614 bytes.
2015-03-03 01:15:19,811 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=623&endTxId=623&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 01:15:19,825 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 102400.00 KB/s
2015-03-03 01:15:19,825 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000623-0000000000000000623_0000001425363319811 size 0 bytes.
2015-03-03 01:15:19,825 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=624&endTxId=625&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 01:15:19,828 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-03-03 01:15:19,828 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000624-0000000000000000625_0000001425363319825 size 0 bytes.
2015-03-03 01:15:19,860 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 73 INodes.
2015-03-03 01:15:19,908 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-03 01:15:19,908 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 622 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000622
2015-03-03 01:15:19,908 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-03 01:15:19,914 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-03-03 01:15:19,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000623-0000000000000000623 expecting start txid #623
2015-03-03 01:15:19,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000623-0000000000000000623
2015-03-03 01:15:19,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000623-0000000000000000623 of size 1048576 edits # 1 loaded in 0 seconds
2015-03-03 01:15:19,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000624-0000000000000000625 expecting start txid #624
2015-03-03 01:15:19,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000624-0000000000000000625
2015-03-03 01:15:19,937 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000624-0000000000000000625 of size 42 edits # 2 loaded in 0 seconds
2015-03-03 01:15:19,987 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 622
2015-03-03 01:15:19,988 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000611, cpktTxId=0000000000000000611)
2015-03-03 01:15:20,065 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 625 to namenode at http://localhost:50070 in 0.066 seconds
2015-03-03 01:15:20,065 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5614
2015-03-03 01:36:21,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:36:22,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:36:23,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:36:24,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:36:25,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:36:26,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:36:27,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:36:28,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:36:29,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:36:30,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:36:30,387 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.37.127 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 17 more
2015-03-03 01:37:31,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:37:32,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:37:33,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:37:34,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:37:35,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:37:36,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:37:37,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:37:38,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:37:39,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:37:40,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:37:40,404 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.37.127 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 17 more
2015-03-03 01:38:41,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:38:42,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:38:43,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:38:44,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:38:45,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:38:46,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:38:47,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:38:48,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:38:49,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:38:50,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:38:50,424 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.37.127 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 17 more
2015-03-03 01:39:51,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:39:52,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:39:53,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:39:54,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:39:55,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:39:56,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:39:57,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:39:58,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:39:59,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:40:00,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:40:00,443 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.37.127 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 17 more
2015-03-03 01:41:01,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:41:02,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:41:03,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:41:04,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:41:05,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:41:06,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:41:07,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:41:08,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:41:09,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:41:10,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:41:10,460 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.37.127 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 17 more
2015-03-03 01:42:11,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:42:12,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:42:13,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:42:14,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:42:15,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:42:16,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:42:17,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:42:18,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:42:19,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:42:20,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:42:20,480 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.37.127 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 17 more
2015-03-03 01:43:21,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:43:22,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:43:23,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:43:24,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:43:25,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:43:26,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:43:27,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:43:28,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:43:29,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:43:30,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:43:30,502 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.37.127 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 17 more
2015-03-03 01:44:31,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:44:32,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:44:33,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:44:34,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:44:35,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:44:36,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:44:37,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:44:38,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:44:39,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:44:40,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:44:40,523 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.37.127 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 17 more
2015-03-03 01:45:41,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:45:42,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:45:43,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:45:44,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:45:45,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:45:46,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:45:47,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:45:48,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:45:49,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:45:50,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:45:50,541 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.37.127 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 17 more
2015-03-03 01:46:51,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:46:52,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:46:53,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-03 01:47:23,601 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-03 01:47:23,614 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.37.127
************************************************************/
2015-03-03 01:47:47,527 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.37.127
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-03 01:47:47,538 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-03 01:47:48,064 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-03 01:47:48,230 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-03 01:47:48,528 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-03 01:47:48,528 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-03 01:47:48,810 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 69067@jays-MacBook-Pro-2.local
2015-03-03 01:47:48,930 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-03 01:47:48,936 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-03 01:47:48,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-03 01:47:48,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-03 01:47:48,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-03 01:47:48,978 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 03 01:47:48
2015-03-03 01:47:48,979 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-03 01:47:48,979 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-03 01:47:48,983 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-03 01:47:48,983 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-03 01:47:48,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-03 01:47:48,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-03 01:47:48,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-03 01:47:48,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-03 01:47:48,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-03 01:47:48,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-03 01:47:48,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-03 01:47:48,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-03 01:47:48,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-03 01:47:49,002 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-03 01:47:49,002 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-03 01:47:49,002 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-03 01:47:49,002 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-03 01:47:49,005 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-03 01:47:49,212 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-03 01:47:49,212 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-03 01:47:49,213 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-03 01:47:49,213 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-03 01:47:49,213 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-03 01:47:49,226 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-03 01:47:49,226 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-03 01:47:49,226 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-03 01:47:49,226 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-03 01:47:49,229 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-03 01:47:49,229 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-03 01:47:49,229 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-03 01:47:49,232 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-03 01:47:49,232 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-03 01:47:49,232 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-03 01:47:49,252 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-03 01:47:49,309 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-03 01:47:49,312 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-03 01:47:49,323 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-03 01:47:49,325 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-03 01:47:49,326 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-03 01:47:49,326 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-03 01:47:49,362 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-03 01:47:49,362 INFO org.mortbay.log: jetty-6.1.26
2015-03-03 01:47:49,619 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-03 01:47:49,619 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-03 01:47:49,620 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-03 01:47:49,620 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-03 01:48:49,789 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-03 01:48:50,200 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=625&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 01:48:50,231 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-03 01:48:50,577 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 833.33 KB/s
2015-03-03 01:48:50,578 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000625 size 5614 bytes.
2015-03-03 01:48:50,583 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=626&endTxId=1107&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 01:48:50,638 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 48761.90 KB/s
2015-03-03 01:48:50,638 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000626-0000000000000001107_0000001425365330583 size 0 bytes.
2015-03-03 01:48:50,640 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1108&endTxId=1108&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 01:48:50,727 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 15515.15 KB/s
2015-03-03 01:48:50,727 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001108-0000000000000001108_0000001425365330639 size 0 bytes.
2015-03-03 01:48:50,728 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1109&endTxId=1110&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 01:48:50,731 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-03-03 01:48:50,732 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001109-0000000000000001110_0000001425365330728 size 0 bytes.
2015-03-03 01:48:50,776 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 73 INodes.
2015-03-03 01:48:50,822 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-03 01:48:50,823 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 625 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000625
2015-03-03 01:48:50,823 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-03 01:48:50,828 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 3 stream(s).
2015-03-03 01:48:50,832 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000626-0000000000000001107 expecting start txid #626
2015-03-03 01:48:50,832 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000626-0000000000000001107
2015-03-03 01:48:50,970 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000626-0000000000000001107 of size 1048576 edits # 482 loaded in 0 seconds
2015-03-03 01:48:50,970 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001108-0000000000000001108 expecting start txid #1108
2015-03-03 01:48:50,970 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001108-0000000000000001108
2015-03-03 01:48:50,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001108-0000000000000001108 of size 1048576 edits # 1 loaded in 0 seconds
2015-03-03 01:48:50,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001109-0000000000000001110 expecting start txid #1109
2015-03-03 01:48:50,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001109-0000000000000001110
2015-03-03 01:48:50,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001109-0000000000000001110 of size 42 edits # 2 loaded in 0 seconds
2015-03-03 01:48:51,025 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 625
2015-03-03 01:48:51,025 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000622, cpktTxId=0000000000000000622)
2015-03-03 01:48:51,063 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1110 to namenode at http://localhost:50070 in 0.025 seconds
2015-03-03 01:48:51,064 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 12120
2015-03-03 02:11:56,692 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.37.127
************************************************************/
2015-03-03 02:17:23,409 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.37.127
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-03 02:17:23,421 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-03 02:17:23,952 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-03 02:17:24,120 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-03 02:17:24,426 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-03 02:17:24,426 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-03 02:17:25,091 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 72464@jays-MacBook-Pro-2.local
2015-03-03 02:17:25,205 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-03 02:17:25,219 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-03 02:17:25,264 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-03 02:17:25,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-03 02:17:25,266 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-03 02:17:25,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 03 02:17:25
2015-03-03 02:17:25,269 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-03 02:17:25,269 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-03 02:17:25,273 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-03 02:17:25,273 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-03 02:17:25,288 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-03 02:17:25,288 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-03 02:17:25,288 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-03 02:17:25,288 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-03 02:17:25,288 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-03 02:17:25,288 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-03 02:17:25,288 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-03 02:17:25,288 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-03 02:17:25,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-03 02:17:25,289 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-03 02:17:25,289 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-03 02:17:25,289 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-03 02:17:25,289 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-03 02:17:25,292 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-03 02:17:25,495 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-03 02:17:25,495 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-03 02:17:25,495 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-03 02:17:25,495 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-03 02:17:25,496 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-03 02:17:25,505 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-03 02:17:25,505 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-03 02:17:25,505 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-03 02:17:25,505 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-03 02:17:25,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-03 02:17:25,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-03 02:17:25,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-03 02:17:25,509 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-03 02:17:25,509 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-03 02:17:25,509 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-03 02:17:25,547 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-03 02:17:25,601 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-03 02:17:25,605 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-03 02:17:25,618 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-03 02:17:25,620 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-03 02:17:25,620 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-03 02:17:25,620 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-03 02:17:25,653 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-03 02:17:25,653 INFO org.mortbay.log: jetty-6.1.26
2015-03-03 02:17:25,907 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-03 02:17:25,907 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-03 02:17:25,908 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-03 02:17:25,908 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-03 02:18:26,168 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-03 02:18:26,617 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=1110&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 02:18:26,671 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-03 02:18:27,041 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 1375.00 KB/s
2015-03-03 02:18:27,041 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001110 size 12120 bytes.
2015-03-03 02:18:27,047 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1111&endTxId=1399&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 02:18:27,059 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 102400.00 KB/s
2015-03-03 02:18:27,059 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001111-0000000000000001399_0000001425367107046 size 0 bytes.
2015-03-03 02:18:27,060 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1400&endTxId=1405&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-03 02:18:27,064 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-03-03 02:18:27,064 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001400-0000000000000001405_0000001425367107060 size 0 bytes.
2015-03-03 02:18:27,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 151 INodes.
2015-03-03 02:18:27,152 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-03 02:18:27,152 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1110 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000001110
2015-03-03 02:18:27,152 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-03 02:18:27,175 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-03-03 02:18:27,180 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001111-0000000000000001399 expecting start txid #1111
2015-03-03 02:18:27,180 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001111-0000000000000001399
2015-03-03 02:18:27,285 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001111-0000000000000001399 of size 1048576 edits # 289 loaded in 0 seconds
2015-03-03 02:18:27,285 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001400-0000000000000001405 expecting start txid #1400
2015-03-03 02:18:27,285 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001400-0000000000000001405
2015-03-03 02:18:27,286 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000001400-0000000000000001405 of size 630 edits # 6 loaded in 0 seconds
2015-03-03 02:18:27,359 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1110
2015-03-03 02:18:27,359 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000625, cpktTxId=0000000000000000625)
2015-03-03 02:18:27,479 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1405 to namenode at http://localhost:50070 in 0.109 seconds
2015-03-03 02:18:27,479 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 12617
2015-03-03 02:32:08,571 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-03 02:32:08,580 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.37.127
************************************************************/
2015-03-04 00:09:47,664 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.37.127
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-04 00:09:47,696 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-04 00:09:48,241 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-04 00:09:48,407 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-04 00:09:48,696 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-04 00:09:48,696 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-04 00:09:49,465 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 86349@jays-MacBook-Pro-2.local
2015-03-04 00:09:49,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-04 00:09:49,582 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-04 00:09:49,624 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-04 00:09:49,624 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-04 00:09:49,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-04 00:09:49,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 04 00:09:49
2015-03-04 00:09:49,631 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-04 00:09:49,631 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 00:09:49,635 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-04 00:09:49,635 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-04 00:09:49,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-04 00:09:49,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-04 00:09:49,651 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-04 00:09:49,651 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-04 00:09:49,651 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-04 00:09:49,651 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-04 00:09:49,651 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-04 00:09:49,651 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-04 00:09:49,651 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-04 00:09:49,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-04 00:09:49,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-04 00:09:49,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-04 00:09:49,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-04 00:09:49,654 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-04 00:09:49,841 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-04 00:09:49,841 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 00:09:49,841 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-04 00:09:49,841 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-04 00:09:49,842 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-04 00:09:49,849 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-04 00:09:49,849 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 00:09:49,849 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-04 00:09:49,849 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-04 00:09:49,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-04 00:09:49,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-04 00:09:49,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-04 00:09:49,853 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-04 00:09:49,853 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-04 00:09:49,853 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-04 00:09:49,864 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-04 00:09:49,911 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-04 00:09:49,915 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-04 00:09:49,925 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-04 00:09:49,927 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-04 00:09:49,927 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-04 00:09:49,928 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-04 00:09:49,957 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-04 00:09:49,957 INFO org.mortbay.log: jetty-6.1.26
2015-03-04 00:09:50,185 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-04 00:09:50,185 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-04 00:09:50,186 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-04 00:09:50,186 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-04 00:10:50,447 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-04 00:10:50,932 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=2001&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 00:10:50,996 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-04 00:10:51,544 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 2000.00 KB/s
2015-03-04 00:10:51,544 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000002001 size 14736 bytes.
2015-03-04 00:10:51,549 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=2002&endTxId=2003&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 00:10:51,572 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-03-04 00:10:51,572 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002002-0000000000000002003_0000001425445851549 size 0 bytes.
2015-03-04 00:10:51,617 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 175 INodes.
2015-03-04 00:10:51,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-04 00:10:51,670 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2001 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000002001
2015-03-04 00:10:51,670 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-04 00:10:51,675 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-04 00:10:51,679 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000002002-0000000000000002003 expecting start txid #2002
2015-03-04 00:10:51,679 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000002002-0000000000000002003
2015-03-04 00:10:51,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000002002-0000000000000002003 of size 42 edits # 2 loaded in 0 seconds
2015-03-04 00:10:51,756 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2001
2015-03-04 00:10:51,757 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000001110, cpktTxId=0000000000000001110)
2015-03-04 00:10:51,758 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000001405, cpktTxId=0000000000000001405)
2015-03-04 00:10:51,874 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2003 to namenode at http://localhost:50070 in 0.105 seconds
2015-03-04 00:10:51,874 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 14736
2015-03-04 01:10:52,536 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-03-04 01:10:52,577 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=2004&endTxId=2992&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 01:10:52,585 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 34666.67 KB/s
2015-03-04 01:10:52,585 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002004-0000000000000002992_0000001425449452577 size 0 bytes.
2015-03-04 01:10:52,586 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-04 01:10:52,586 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000002004-0000000000000002992 expecting start txid #2004
2015-03-04 01:10:52,586 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000002004-0000000000000002992
2015-03-04 01:10:52,793 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000002004-0000000000000002992 of size 106711 edits # 989 loaded in 0 seconds
2015-03-04 01:10:52,832 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2003
2015-03-04 01:10:52,832 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000002001, cpktTxId=0000000000000002001)
2015-03-04 01:10:52,851 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2992 to namenode at http://localhost:50070 in 0.014 seconds
2015-03-04 01:10:52,851 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 27316
2015-03-04 01:19:20,148 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-04 01:19:20,150 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.37.127
************************************************************/
2015-03-04 01:20:22,530 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.37.127
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-04 01:20:22,542 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-04 01:20:23,104 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-04 01:20:23,267 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-04 01:20:23,578 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-04 01:20:23,578 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-04 01:20:23,889 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 94553@jays-MacBook-Pro-2.local
2015-03-04 01:20:23,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-04 01:20:23,967 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-04 01:20:24,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-04 01:20:24,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-04 01:20:24,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-04 01:20:24,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 04 01:20:24
2015-03-04 01:20:24,012 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-04 01:20:24,012 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 01:20:24,016 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-04 01:20:24,016 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-04 01:20:24,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-04 01:20:24,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-04 01:20:24,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-04 01:20:24,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-04 01:20:24,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-04 01:20:24,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-04 01:20:24,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-04 01:20:24,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-04 01:20:24,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-04 01:20:24,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-04 01:20:24,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-04 01:20:24,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-04 01:20:24,032 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-04 01:20:24,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-04 01:20:24,237 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-04 01:20:24,237 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 01:20:24,237 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-04 01:20:24,237 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-04 01:20:24,238 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-04 01:20:24,248 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-04 01:20:24,248 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 01:20:24,249 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-04 01:20:24,249 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-04 01:20:24,251 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-04 01:20:24,251 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-04 01:20:24,251 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-04 01:20:24,254 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-04 01:20:24,254 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-04 01:20:24,254 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-04 01:20:24,267 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-04 01:20:24,329 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-04 01:20:24,333 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-04 01:20:24,351 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-04 01:20:24,354 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-04 01:20:24,354 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-04 01:20:24,355 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-04 01:20:24,398 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-04 01:20:24,398 INFO org.mortbay.log: jetty-6.1.26
2015-03-04 01:20:24,644 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-04 01:20:24,644 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-04 01:20:24,645 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-04 01:20:24,645 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-04 01:21:24,820 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-04 01:21:25,221 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=2992&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 01:21:25,264 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-04 01:21:25,795 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 541.67 KB/s
2015-03-04 01:21:25,795 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000002992 size 27316 bytes.
2015-03-04 01:21:25,801 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=2993&endTxId=3077&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 01:21:25,818 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 78769.23 KB/s
2015-03-04 01:21:25,818 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002993-0000000000000003077_0000001425450085801 size 0 bytes.
2015-03-04 01:21:25,819 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=3078&endTxId=3229&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 01:21:25,822 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 19000.00 KB/s
2015-03-04 01:21:25,822 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003078-0000000000000003229_0000001425450085819 size 0 bytes.
2015-03-04 01:21:25,880 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 327 INodes.
2015-03-04 01:21:25,957 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-04 01:21:25,957 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2992 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000002992
2015-03-04 01:21:25,957 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-04 01:21:25,965 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-03-04 01:21:25,969 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000002993-0000000000000003077 expecting start txid #2993
2015-03-04 01:21:25,970 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000002993-0000000000000003077
2015-03-04 01:21:26,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000002993-0000000000000003077 of size 1048576 edits # 85 loaded in 0 seconds
2015-03-04 01:21:26,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000003078-0000000000000003229 expecting start txid #3078
2015-03-04 01:21:26,059 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000003078-0000000000000003229
2015-03-04 01:21:26,095 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000003078-0000000000000003229 of size 19901 edits # 152 loaded in 0 seconds
2015-03-04 01:21:26,171 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2992
2015-03-04 01:21:26,171 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000002003, cpktTxId=0000000000000002003)
2015-03-04 01:21:26,224 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3229 to namenode at http://localhost:50070 in 0.038 seconds
2015-03-04 01:21:26,224 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 30294
2015-03-04 01:54:26,813 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "jays-MacBook-Pro-2.local/10.190.37.127"; destination host is: "localhost":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:198)
	at sun.nio.ch.IOUtil.read(IOUtil.java:171)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:245)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:116)
	at java.io.FilterInputStream.read(FilterInputStream.java:116)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:513)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:237)
	at java.io.DataInputStream.readInt(DataInputStream.java:370)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1071)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:966)
2015-03-04 01:54:38,108 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-04 01:54:38,110 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.37.127
************************************************************/
2015-03-04 01:56:35,967 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.37.127
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-04 01:56:35,979 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-04 01:56:36,479 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-04 01:56:36,643 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-04 01:56:36,938 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-04 01:56:36,938 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-04 01:56:37,280 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 6034@jays-MacBook-Pro-2.local
2015-03-04 01:56:37,405 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-04 01:56:37,416 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-04 01:56:37,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-04 01:56:37,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-04 01:56:37,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-04 01:56:37,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 04 01:56:37
2015-03-04 01:56:37,465 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-04 01:56:37,465 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 01:56:37,470 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-04 01:56:37,470 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-04 01:56:37,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-04 01:56:37,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-04 01:56:37,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-04 01:56:37,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-04 01:56:37,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-04 01:56:37,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-04 01:56:37,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-04 01:56:37,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-04 01:56:37,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-04 01:56:37,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-04 01:56:37,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-04 01:56:37,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-04 01:56:37,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-04 01:56:37,489 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-04 01:56:37,689 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-04 01:56:37,689 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 01:56:37,689 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-04 01:56:37,689 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-04 01:56:37,690 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-04 01:56:37,699 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-04 01:56:37,699 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 01:56:37,699 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-04 01:56:37,699 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-04 01:56:37,700 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-04 01:56:37,701 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-04 01:56:37,701 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-04 01:56:37,703 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-04 01:56:37,703 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-04 01:56:37,703 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-04 01:56:37,750 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-04 01:56:37,802 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-04 01:56:37,806 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-04 01:56:37,817 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-04 01:56:37,820 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-04 01:56:37,820 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-04 01:56:37,820 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-04 01:56:37,852 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-04 01:56:37,852 INFO org.mortbay.log: jetty-6.1.26
2015-03-04 01:56:38,096 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-04 01:56:38,096 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-04 01:56:38,097 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-04 01:56:38,097 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-04 01:57:38,436 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-04 01:57:40,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=3229&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 01:57:40,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-04 01:57:41,070 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 2636.36 KB/s
2015-03-04 01:57:41,070 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000003229 size 30294 bytes.
2015-03-04 01:57:41,077 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=3230&endTxId=4493&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 01:57:41,095 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 68266.67 KB/s
2015-03-04 01:57:41,095 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003230-0000000000000004493_0000001425452261077 size 0 bytes.
2015-03-04 01:57:41,096 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=4494&endTxId=4690&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 01:57:41,100 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 21000.00 KB/s
2015-03-04 01:57:41,100 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004494-0000000000000004690_0000001425452261096 size 0 bytes.
2015-03-04 01:57:41,150 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 360 INodes.
2015-03-04 01:57:41,219 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-04 01:57:41,219 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 3229 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000003229
2015-03-04 01:57:41,219 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-04 01:57:41,226 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-03-04 01:57:41,230 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000003230-0000000000000004493 expecting start txid #3230
2015-03-04 01:57:41,230 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000003230-0000000000000004493
2015-03-04 01:57:41,476 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000003230-0000000000000004493 of size 1048576 edits # 1264 loaded in 0 seconds
2015-03-04 01:57:41,476 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000004494-0000000000000004690 expecting start txid #4494
2015-03-04 01:57:41,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000004494-0000000000000004690
2015-03-04 01:57:41,513 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000004494-0000000000000004690 of size 21719 edits # 197 loaded in 0 seconds
2015-03-04 01:57:41,625 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3229
2015-03-04 01:57:41,625 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000002992, cpktTxId=0000000000000002992)
2015-03-04 01:57:41,764 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4690 to namenode at http://localhost:50070 in 0.117 seconds
2015-03-04 01:57:41,765 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 32765
2015-03-04 02:07:42,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-04 02:07:43,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-04 02:07:44,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-04 02:07:45,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-04 02:07:46,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-04 02:07:47,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-04 02:07:48,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-04 02:07:49,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-04 02:07:50,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-04 02:07:51,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-04 02:07:51,851 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.37.127 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 18 more
2015-03-04 02:07:52,396 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-04 02:07:52,398 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.37.127
************************************************************/
2015-03-04 02:29:28,527 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.37.127
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-04 02:29:28,540 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-04 02:29:29,110 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-04 02:29:29,292 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-04 02:29:29,594 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-04 02:29:29,594 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-04 02:29:29,898 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 11903@jays-MacBook-Pro-2.local
2015-03-04 02:29:29,983 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-04 02:29:29,989 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-04 02:29:30,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-04 02:29:30,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-04 02:29:30,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-04 02:29:30,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 04 02:29:30
2015-03-04 02:29:30,037 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-04 02:29:30,037 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 02:29:30,041 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-04 02:29:30,041 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-04 02:29:30,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-04 02:29:30,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-04 02:29:30,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-04 02:29:30,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-04 02:29:30,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-04 02:29:30,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-04 02:29:30,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-04 02:29:30,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-04 02:29:30,062 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-04 02:29:30,062 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-04 02:29:30,062 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-04 02:29:30,062 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-04 02:29:30,063 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-04 02:29:30,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-04 02:29:30,269 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-04 02:29:30,269 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 02:29:30,269 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-04 02:29:30,269 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-04 02:29:30,270 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-04 02:29:30,280 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-04 02:29:30,280 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 02:29:30,280 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-04 02:29:30,280 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-04 02:29:30,283 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-04 02:29:30,283 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-04 02:29:30,283 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-04 02:29:30,285 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-04 02:29:30,285 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-04 02:29:30,286 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-04 02:29:30,328 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-04 02:29:30,381 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-04 02:29:30,385 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-04 02:29:30,397 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-04 02:29:30,400 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-04 02:29:30,400 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-04 02:29:30,400 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-04 02:29:30,439 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-04 02:29:30,439 INFO org.mortbay.log: jetty-6.1.26
2015-03-04 02:29:30,683 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-04 02:29:30,683 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-04 02:29:30,684 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-04 02:29:30,684 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-04 02:30:31,378 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-04 02:30:31,930 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=4690&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 02:30:31,982 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-04 02:30:32,389 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 3100.00 KB/s
2015-03-04 02:30:32,389 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004690 size 32765 bytes.
2015-03-04 02:30:32,395 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=4691&endTxId=5193&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 02:30:32,413 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 73142.86 KB/s
2015-03-04 02:30:32,413 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004691-0000000000000005193_0000001425454232395 size 0 bytes.
2015-03-04 02:30:32,414 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=5194&endTxId=5304&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 02:30:32,417 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 14000.00 KB/s
2015-03-04 02:30:32,417 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005194-0000000000000005304_0000001425454232413 size 0 bytes.
2015-03-04 02:30:32,453 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 388 INodes.
2015-03-04 02:30:32,524 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-04 02:30:32,524 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4690 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000004690
2015-03-04 02:30:32,524 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-04 02:30:32,529 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-03-04 02:30:32,533 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000004691-0000000000000005193 expecting start txid #4691
2015-03-04 02:30:32,533 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000004691-0000000000000005193
2015-03-04 02:30:32,661 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000004691-0000000000000005193 of size 1048576 edits # 503 loaded in 0 seconds
2015-03-04 02:30:32,661 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005194-0000000000000005304 expecting start txid #5194
2015-03-04 02:30:32,661 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005194-0000000000000005304
2015-03-04 02:30:32,679 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005194-0000000000000005304 of size 14369 edits # 111 loaded in 0 seconds
2015-03-04 02:30:32,782 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4690
2015-03-04 02:30:32,782 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000003229, cpktTxId=0000000000000003229)
2015-03-04 02:30:32,897 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5304 to namenode at http://localhost:50070 in 0.101 seconds
2015-03-04 02:30:32,898 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 33147
2015-03-04 06:21:47,908 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-03-04 06:21:47,909 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=5305&endTxId=5447&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 06:21:48,507 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.58s at 31.30 KB/s
2015-03-04 06:21:48,531 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005305-0000000000000005447_0000001425468107909 size 0 bytes.
2015-03-04 06:21:48,645 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-04 06:21:48,646 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005305-0000000000000005447 expecting start txid #5305
2015-03-04 06:21:48,646 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005305-0000000000000005447
2015-03-04 06:21:48,670 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005305-0000000000000005447 of size 18790 edits # 143 loaded in 0 seconds
2015-03-04 06:21:48,985 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5304
2015-03-04 06:21:48,986 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000004690, cpktTxId=0000000000000004690)
2015-03-04 06:21:49,917 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5447 to namenode at http://localhost:50070 in 0.829 seconds
2015-03-04 06:21:49,918 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 33147
2015-03-04 08:10:40,050 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-03-04 08:10:40,050 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=5448&endTxId=5449&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 08:10:40,065 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2015-03-04 08:10:40,065 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005448-0000000000000005449_0000001425474640050 size 0 bytes.
2015-03-04 08:10:40,066 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-04 08:10:40,066 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005448-0000000000000005449 expecting start txid #5448
2015-03-04 08:10:40,066 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005448-0000000000000005449
2015-03-04 08:10:40,067 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005448-0000000000000005449 of size 42 edits # 2 loaded in 0 seconds
2015-03-04 08:10:40,110 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5447
2015-03-04 08:10:40,110 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000005304, cpktTxId=0000000000000005304)
2015-03-04 08:10:40,491 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5449 to namenode at http://localhost:50070 in 0.101 seconds
2015-03-04 08:10:40,491 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 33147
2015-03-04 09:50:20,197 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-03-04 09:50:20,197 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=5450&endTxId=5451&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 09:50:20,202 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-03-04 09:50:20,202 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005450-0000000000000005451_0000001425480620197 size 0 bytes.
2015-03-04 09:50:20,203 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-04 09:50:20,203 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005450-0000000000000005451 expecting start txid #5450
2015-03-04 09:50:20,203 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005450-0000000000000005451
2015-03-04 09:50:20,203 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005450-0000000000000005451 of size 42 edits # 2 loaded in 0 seconds
2015-03-04 09:50:20,517 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5449
2015-03-04 09:50:20,518 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000005447, cpktTxId=0000000000000005447)
2015-03-04 09:50:20,619 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5451 to namenode at http://localhost:50070 in 0.083 seconds
2015-03-04 09:50:20,620 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 33147
2015-03-04 09:51:01,864 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-04 09:51:01,866 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.37.127
************************************************************/
2015-03-04 11:26:39,841 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.115.76
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-04 11:26:39,884 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-04 11:26:40,456 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-04 11:26:40,632 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-04 11:26:40,940 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-04 11:26:40,941 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-04 11:26:41,433 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 16638@jays-MacBook-Pro-2.local
2015-03-04 11:26:41,548 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-04 11:26:41,554 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-04 11:26:41,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-04 11:26:41,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-04 11:26:41,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-04 11:26:41,599 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 04 11:26:41
2015-03-04 11:26:41,601 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-04 11:26:41,601 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 11:26:41,604 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-04 11:26:41,604 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-04 11:26:41,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-04 11:26:41,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-04 11:26:41,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-04 11:26:41,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-04 11:26:41,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-04 11:26:41,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-04 11:26:41,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-04 11:26:41,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-04 11:26:41,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-04 11:26:41,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-04 11:26:41,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-04 11:26:41,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-04 11:26:41,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-04 11:26:41,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-04 11:26:41,814 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-04 11:26:41,814 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 11:26:41,814 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-04 11:26:41,814 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-04 11:26:41,815 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-04 11:26:41,823 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-04 11:26:41,823 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-04 11:26:41,823 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-04 11:26:41,823 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-04 11:26:41,825 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-04 11:26:41,825 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-04 11:26:41,825 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-04 11:26:41,827 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-04 11:26:41,827 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-04 11:26:41,827 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-04 11:26:41,866 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-04 11:26:41,926 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-04 11:26:41,930 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-04 11:26:41,943 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-04 11:26:41,945 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-04 11:26:41,945 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-04 11:26:41,945 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-04 11:26:41,976 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-04 11:26:41,976 INFO org.mortbay.log: jetty-6.1.26
2015-03-04 11:26:42,214 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-04 11:26:42,214 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-04 11:26:42,215 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-04 11:26:42,215 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-04 11:27:42,478 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-04 11:27:42,991 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=5452&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 11:27:43,051 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-04 11:27:43,583 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 3200.00 KB/s
2015-03-04 11:27:43,583 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005452 size 33147 bytes.
2015-03-04 11:27:43,588 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=5453&endTxId=5660&storageInfo=-60:1056499823:0:CID-1b46bba1-467f-49ef-a9a0-cb7c49d311db
2015-03-04 11:27:43,619 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 22000.00 KB/s
2015-03-04 11:27:43,619 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005453-0000000000000005660_0000001425486463588 size 0 bytes.
2015-03-04 11:27:43,673 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 393 INodes.
2015-03-04 11:27:43,738 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-04 11:27:43,738 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 5452 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000005452
2015-03-04 11:27:43,738 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-04 11:27:43,744 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-04 11:27:43,748 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005453-0000000000000005660 expecting start txid #5453
2015-03-04 11:27:43,748 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005453-0000000000000005660
2015-03-04 11:27:43,835 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000005453-0000000000000005660 of size 22582 edits # 208 loaded in 0 seconds
2015-03-04 11:27:43,907 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5452
2015-03-04 11:27:43,907 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000005449, cpktTxId=0000000000000005449)
2015-03-04 11:27:43,908 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000005451, cpktTxId=0000000000000005451)
2015-03-04 11:27:44,038 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5660 to namenode at http://localhost:50070 in 0.113 seconds
2015-03-04 11:27:44,038 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 35595
2015-03-04 11:31:06,107 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-04 11:31:06,108 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.115.76
************************************************************/
2015-03-05 00:29:19,181 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.34.79
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-05 00:29:19,260 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-05 00:29:19,852 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-05 00:29:20,026 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-05 00:29:20,323 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-05 00:29:20,323 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-05 00:29:20,811 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 22551@jays-MacBook-Pro-2.local
2015-03-05 00:29:20,926 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-05 00:29:20,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-05 00:29:20,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-05 00:29:20,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-05 00:29:20,977 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-05 00:29:20,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 05 00:29:20
2015-03-05 00:29:20,981 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-05 00:29:20,981 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 00:29:20,984 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-05 00:29:20,985 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-05 00:29:21,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-05 00:29:21,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-05 00:29:21,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-05 00:29:21,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-05 00:29:21,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-05 00:29:21,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-05 00:29:21,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-05 00:29:21,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-05 00:29:21,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-05 00:29:21,006 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-05 00:29:21,006 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-05 00:29:21,006 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-05 00:29:21,006 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-05 00:29:21,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-05 00:29:21,202 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-05 00:29:21,202 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 00:29:21,202 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-05 00:29:21,202 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-05 00:29:21,203 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-05 00:29:21,211 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-05 00:29:21,211 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 00:29:21,212 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-05 00:29:21,212 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-05 00:29:21,213 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-05 00:29:21,213 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-05 00:29:21,213 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-05 00:29:21,215 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-05 00:29:21,215 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-05 00:29:21,215 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-05 00:29:21,228 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-05 00:29:21,276 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-05 00:29:21,280 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-05 00:29:21,294 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-05 00:29:21,296 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-05 00:29:21,297 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-05 00:29:21,297 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-05 00:29:21,327 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-05 00:29:21,327 INFO org.mortbay.log: jetty-6.1.26
2015-03-05 00:29:21,572 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-05 00:29:21,572 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-05 00:29:21,573 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-05 00:29:21,573 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-05 00:30:21,697 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 303 needs additional 46 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1364)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:6340)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:933)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:394)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
2015-03-05 00:31:21,722 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 303 needs additional 46 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1364)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:6340)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:933)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:394)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
2015-03-05 00:32:21,737 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 303 needs additional 46 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1364)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:6340)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:933)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:394)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
2015-03-05 00:33:21,763 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 303 needs additional 46 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1364)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:6340)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:933)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:394)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
2015-03-05 00:34:21,838 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 303 needs additional 46 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1364)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:6340)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:933)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:394)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
2015-03-05 00:34:39,021 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-05 00:34:39,023 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.34.79
************************************************************/
2015-03-05 00:35:01,510 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.34.79
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-05 00:35:01,521 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-05 00:35:02,094 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-05 00:35:02,266 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-05 00:35:02,633 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-05 00:35:02,633 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-05 00:35:03,003 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 23913@jays-MacBook-Pro-2.local
2015-03-05 00:35:03,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-05 00:35:03,128 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-05 00:35:03,172 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-05 00:35:03,172 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-05 00:35:03,173 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-05 00:35:03,175 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 05 00:35:03
2015-03-05 00:35:03,177 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-05 00:35:03,177 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 00:35:03,181 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-05 00:35:03,181 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-05 00:35:03,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-05 00:35:03,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-05 00:35:03,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-05 00:35:03,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-05 00:35:03,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-05 00:35:03,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-05 00:35:03,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-05 00:35:03,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-05 00:35:03,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-05 00:35:03,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-05 00:35:03,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-05 00:35:03,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-05 00:35:03,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-05 00:35:03,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-05 00:35:03,392 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-05 00:35:03,392 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 00:35:03,392 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-05 00:35:03,392 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-05 00:35:03,393 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-05 00:35:03,401 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-05 00:35:03,401 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 00:35:03,401 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-05 00:35:03,401 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-05 00:35:03,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-05 00:35:03,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-05 00:35:03,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-05 00:35:03,405 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-05 00:35:03,405 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-05 00:35:03,405 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-05 00:35:03,460 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-05 00:35:03,511 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-05 00:35:03,515 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-05 00:35:03,529 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-05 00:35:03,532 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-05 00:35:03,532 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-05 00:35:03,532 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-05 00:35:03,562 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-05 00:35:03,562 INFO org.mortbay.log: jetty-6.1.26
2015-03-05 00:35:03,816 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-05 00:35:03,816 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-05 00:35:03,817 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-05 00:35:03,817 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-05 00:36:03,905 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 303 needs additional 46 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1364)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:6340)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:933)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:394)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
2015-03-05 00:37:03,919 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 303 needs additional 46 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1364)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:6340)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:933)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:394)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
2015-03-05 00:38:03,929 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 303 needs additional 46 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1364)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:6340)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:933)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:394)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
2015-03-05 00:39:03,940 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
The reported blocks 303 needs additional 46 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1364)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:6340)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:933)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:394)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
2015-03-05 00:39:36,179 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-05 00:39:36,180 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.34.79
************************************************************/
2015-03-05 01:30:27,735 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.34.79
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-05 01:30:27,907 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-05 01:30:28,432 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-05 01:30:28,614 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-05 01:30:29,144 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-05 01:30:29,144 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-05 01:30:31,254 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 1134@jays-MacBook-Pro-2.local
2015-03-05 01:30:31,282 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-05 01:30:31,289 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-05 01:30:31,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-05 01:30:31,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-05 01:30:31,332 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-05 01:30:31,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 05 01:30:31
2015-03-05 01:30:31,336 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-05 01:30:31,336 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 01:30:31,340 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-05 01:30:31,340 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-05 01:30:31,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-05 01:30:31,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-05 01:30:31,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-05 01:30:31,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-05 01:30:31,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-05 01:30:31,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-05 01:30:31,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-05 01:30:31,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-05 01:30:31,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-05 01:30:31,361 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-05 01:30:31,361 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-05 01:30:31,361 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-05 01:30:31,361 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-05 01:30:31,364 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-05 01:30:31,536 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-05 01:30:31,536 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 01:30:31,536 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-05 01:30:31,536 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-05 01:30:31,562 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-05 01:30:31,571 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-05 01:30:31,571 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 01:30:31,572 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-05 01:30:31,572 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-05 01:30:31,573 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-05 01:30:31,573 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-05 01:30:31,573 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-05 01:30:31,575 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-05 01:30:31,575 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-05 01:30:31,575 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-05 01:30:31,626 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-05 01:30:31,676 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-05 01:30:31,680 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-05 01:30:31,694 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-05 01:30:31,696 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-05 01:30:31,696 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-05 01:30:31,696 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-05 01:30:31,730 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-05 01:30:31,731 INFO org.mortbay.log: jetty-6.1.26
2015-03-05 01:30:32,003 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-05 01:30:32,003 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-05 01:30:32,004 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-05 01:30:32,004 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-05 01:31:33,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:31:34,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:31:35,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:31:36,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:31:37,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:31:38,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:31:39,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:31:40,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:31:41,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:31:42,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:31:42,087 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.34.79 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 18 more
2015-03-05 01:32:43,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:32:44,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:32:45,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:32:46,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:32:47,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:32:48,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:32:49,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:32:50,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:32:51,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:32:52,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:32:52,129 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.34.79 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 18 more
2015-03-05 01:33:53,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:33:54,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:33:55,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:33:56,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:33:57,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:33:58,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:33:59,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:34:00,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:34:01,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:34:02,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:34:02,152 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.34.79 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 18 more
2015-03-05 01:34:43,676 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-05 01:34:43,689 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.34.79
************************************************************/
2015-03-05 01:35:23,772 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.34.79
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-05 01:35:23,785 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-05 01:35:24,383 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-05 01:35:24,633 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-05 01:35:25,077 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-05 01:35:25,077 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-05 01:35:25,521 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 2449@jays-MacBook-Pro-2.local
2015-03-05 01:35:25,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-05 01:35:25,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-05 01:35:25,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-05 01:35:25,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-05 01:35:25,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-05 01:35:25,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 05 01:35:25
2015-03-05 01:35:25,599 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-05 01:35:25,599 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 01:35:25,604 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-05 01:35:25,604 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-05 01:35:25,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-05 01:35:25,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-05 01:35:25,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-05 01:35:25,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-05 01:35:25,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-05 01:35:25,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-05 01:35:25,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-05 01:35:25,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-05 01:35:25,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-05 01:35:25,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-05 01:35:25,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-05 01:35:25,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-05 01:35:25,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-05 01:35:25,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-05 01:35:25,809 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-05 01:35:25,809 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 01:35:25,809 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-05 01:35:25,810 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-05 01:35:25,830 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-05 01:35:25,839 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-05 01:35:25,839 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 01:35:25,840 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-05 01:35:25,840 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-05 01:35:25,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-05 01:35:25,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-05 01:35:25,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-05 01:35:25,844 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-05 01:35:25,844 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-05 01:35:25,844 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-05 01:35:25,857 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-05 01:35:25,916 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-05 01:35:25,921 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-05 01:35:25,936 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-05 01:35:25,938 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-05 01:35:25,939 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-05 01:35:25,939 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-05 01:35:25,974 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-05 01:35:25,974 INFO org.mortbay.log: jetty-6.1.26
2015-03-05 01:35:26,215 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-05 01:35:26,215 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-05 01:35:26,216 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-05 01:35:26,216 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-05 01:36:27,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:36:28,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:36:29,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:36:30,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:36:31,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:36:32,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:36:33,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:36:34,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:36:35,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:36:36,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:36:36,276 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.34.79 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 18 more
2015-03-05 01:37:37,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:37:38,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:37:39,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:37:40,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:37:41,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:37:42,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:37:43,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:37:44,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:37:45,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:37:46,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:37:46,310 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.34.79 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 18 more
2015-03-05 01:38:47,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:38:48,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:38:49,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:38:50,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:38:51,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:38:52,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:38:53,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:38:54,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:38:55,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:38:56,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:38:56,331 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.34.79 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 18 more
2015-03-05 01:39:57,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:39:58,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:39:59,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:40:00,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:40:01,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:40:02,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:40:03,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:40:04,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:40:05,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:40:06,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-05 01:40:06,346 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.34.79 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 18 more
2015-03-05 01:40:09,152 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-05 01:40:09,164 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.34.79
************************************************************/
2015-03-05 01:43:38,814 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.34.79
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-05 01:43:38,825 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-05 01:43:39,324 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-05 01:43:39,491 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-05 01:43:39,765 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-05 01:43:39,765 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-05 01:43:40,030 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 3890@jays-MacBook-Pro-2.local
2015-03-05 01:43:40,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-05 01:43:40,040 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-05 01:43:40,083 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-05 01:43:40,083 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-05 01:43:40,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-05 01:43:40,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 05 01:43:40
2015-03-05 01:43:40,087 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-05 01:43:40,088 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 01:43:40,094 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-05 01:43:40,094 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-05 01:43:40,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-05 01:43:40,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-05 01:43:40,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-05 01:43:40,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-05 01:43:40,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-05 01:43:40,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-05 01:43:40,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-05 01:43:40,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-05 01:43:40,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-05 01:43:40,115 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-05 01:43:40,115 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-05 01:43:40,115 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-05 01:43:40,115 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-05 01:43:40,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-05 01:43:40,286 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-05 01:43:40,286 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 01:43:40,286 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-05 01:43:40,286 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-05 01:43:40,307 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-05 01:43:40,314 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-05 01:43:40,314 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-05 01:43:40,314 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-05 01:43:40,314 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-05 01:43:40,315 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-05 01:43:40,315 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-05 01:43:40,315 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-05 01:43:40,317 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-05 01:43:40,317 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-05 01:43:40,317 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-05 01:43:40,332 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-05 01:43:40,385 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-05 01:43:40,388 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-05 01:43:40,400 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-05 01:43:40,402 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-05 01:43:40,402 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-05 01:43:40,402 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-05 01:43:40,436 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-05 01:43:40,436 INFO org.mortbay.log: jetty-6.1.26
2015-03-05 01:43:40,645 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-05 01:43:40,645 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-05 01:43:40,646 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-05 01:43:40,646 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-05 01:44:40,920 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-05 01:44:41,444 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:176267982:0:CID-2d274ddb-4bdb-4bf8-910a-7a8ecac9d9ef
2015-03-05 01:44:41,513 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-05 01:44:41,937 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 0.00 KB/s
2015-03-05 01:44:41,937 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 353 bytes.
2015-03-05 01:44:41,942 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-60:176267982:0:CID-2d274ddb-4bdb-4bf8-910a-7a8ecac9d9ef
2015-03-05 01:44:41,946 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-03-05 01:44:41,946 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000001425537881942 size 0 bytes.
2015-03-05 01:44:41,977 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-03-05 01:44:42,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-05 01:44:42,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000000
2015-03-05 01:44:42,005 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-05 01:44:42,011 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-05 01:44:42,015 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2015-03-05 01:44:42,015 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002
2015-03-05 01:44:42,032 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2015-03-05 01:44:42,073 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-jaywang/dfs/namesecondary
2015-03-05 01:44:42,172 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://localhost:50070 in 0.093 seconds
2015-03-05 01:44:42,173 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 353
2015-03-05 02:14:59,497 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-05 02:14:59,499 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.34.79
************************************************************/
2015-03-23 15:12:21,793 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.40.24
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-23 15:12:21,860 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-23 15:12:22,377 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-23 15:12:22,541 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-23 15:12:22,819 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-23 15:12:22,819 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-23 15:12:23,301 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 9398@jays-MacBook-Pro-2.local
2015-03-23 15:12:23,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-23 15:12:23,328 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-23 15:12:23,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-23 15:12:23,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-23 15:12:23,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-23 15:12:23,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 23 15:12:23
2015-03-23 15:12:23,373 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-23 15:12:23,373 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-23 15:12:23,376 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-23 15:12:23,376 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-23 15:12:23,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-23 15:12:23,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-23 15:12:23,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-23 15:12:23,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-23 15:12:23,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-23 15:12:23,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-23 15:12:23,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-23 15:12:23,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-23 15:12:23,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-23 15:12:23,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-23 15:12:23,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-23 15:12:23,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-23 15:12:23,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-23 15:12:23,399 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-23 15:12:23,560 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-23 15:12:23,560 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-23 15:12:23,561 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-23 15:12:23,561 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-23 15:12:23,582 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-23 15:12:23,590 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-23 15:12:23,590 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-23 15:12:23,590 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-23 15:12:23,590 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-23 15:12:23,591 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-23 15:12:23,591 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-23 15:12:23,591 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-23 15:12:23,593 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-23 15:12:23,593 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-23 15:12:23,593 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-23 15:12:23,682 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-23 15:12:23,729 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-23 15:12:23,733 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-23 15:12:23,744 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-23 15:12:23,746 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-23 15:12:23,746 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-23 15:12:23,747 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-23 15:12:23,777 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-23 15:12:23,777 INFO org.mortbay.log: jetty-6.1.26
2015-03-23 15:12:24,002 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-23 15:12:24,002 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-23 15:12:24,003 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-23 15:12:24,003 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-23 15:13:25,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:13:26,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:13:27,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:13:28,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:13:29,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:13:30,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:13:31,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:13:32,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:13:33,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:13:34,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:13:34,083 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.40.24 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 18 more
2015-03-23 15:14:35,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:14:36,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:14:37,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:14:38,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:14:39,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:14:40,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:14:41,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:14:42,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:14:43,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:14:44,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:14:44,104 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.40.24 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 18 more
2015-03-23 15:15:45,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:15:46,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:15:47,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:15:48,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:15:49,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:15:50,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:15:51,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:15:52,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:15:53,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:15:54,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-03-23 15:15:54,123 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From jays-MacBook-Pro-2.local/10.190.40.24 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 18 more
2015-03-23 15:16:08,347 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-23 15:16:08,348 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.40.24
************************************************************/
2015-03-23 15:17:30,597 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.40.24
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-23 15:17:30,608 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-23 15:17:31,117 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-23 15:17:31,281 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-23 15:17:31,550 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-23 15:17:31,550 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-23 15:17:31,815 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 9999@jays-MacBook-Pro-2.local
2015-03-23 15:17:31,822 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-23 15:17:31,829 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-23 15:17:31,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-23 15:17:31,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-23 15:17:31,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-23 15:17:31,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 23 15:17:31
2015-03-23 15:17:31,878 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-23 15:17:31,878 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-23 15:17:31,882 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-23 15:17:31,882 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-23 15:17:31,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-23 15:17:31,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-23 15:17:31,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-23 15:17:31,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-23 15:17:31,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-23 15:17:31,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-23 15:17:31,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-23 15:17:31,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-23 15:17:31,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-23 15:17:31,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-23 15:17:31,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-23 15:17:31,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-23 15:17:31,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-23 15:17:31,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-23 15:17:32,070 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-23 15:17:32,070 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-23 15:17:32,071 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-23 15:17:32,071 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-23 15:17:32,092 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-23 15:17:32,099 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-23 15:17:32,099 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-23 15:17:32,100 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-23 15:17:32,100 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-23 15:17:32,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-23 15:17:32,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-23 15:17:32,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-23 15:17:32,103 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-23 15:17:32,103 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-23 15:17:32,103 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-23 15:17:32,113 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-23 15:17:32,159 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-23 15:17:32,163 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-23 15:17:32,174 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-23 15:17:32,176 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-23 15:17:32,177 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-23 15:17:32,177 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-23 15:17:32,208 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-23 15:17:32,208 INFO org.mortbay.log: jetty-6.1.26
2015-03-23 15:17:32,426 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-23 15:17:32,426 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-23 15:17:32,427 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-23 15:17:32,427 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-23 15:18:32,786 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-23 15:18:33,293 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:1910406943:0:CID-ee3d8ff1-8579-49a9-a16f-57ba16abf638
2015-03-23 15:18:33,382 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-23 15:18:33,962 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2015-03-23 15:18:33,962 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 354 bytes.
2015-03-23 15:18:33,969 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-60:1910406943:0:CID-ee3d8ff1-8579-49a9-a16f-57ba16abf638
2015-03-23 15:18:33,972 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-03-23 15:18:33,972 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000001427138313968 size 0 bytes.
2015-03-23 15:18:34,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-03-23 15:18:34,040 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-23 15:18:34,040 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000000
2015-03-23 15:18:34,040 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-23 15:18:34,047 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-23 15:18:34,053 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2015-03-23 15:18:34,053 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002
2015-03-23 15:18:34,083 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2015-03-23 15:18:34,129 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-jaywang/dfs/namesecondary
2015-03-23 15:18:34,241 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://localhost:50070 in 0.103 seconds
2015-03-23 15:18:34,242 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 354
2015-03-23 16:06:34,925 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "jays-MacBook-Pro-2.local/10.190.40.24"; destination host is: "localhost":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:125)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:695)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:198)
	at sun.nio.ch.IOUtil.read(IOUtil.java:171)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:245)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:116)
	at java.io.FilterInputStream.read(FilterInputStream.java:116)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:513)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:237)
	at java.io.DataInputStream.readInt(DataInputStream.java:370)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1071)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:966)
2015-03-23 16:06:46,216 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-23 16:06:46,218 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.40.24
************************************************************/
2015-03-23 23:57:36,605 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = jays-MacBook-Pro-2.local/10.190.38.245
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /Users/jaywang/Desktop/data/hadoop-2.6.0/etc/hadoop:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/Users/jaywang/Desktop/data/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.6.0_65
************************************************************/
2015-03-23 23:57:36,659 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-03-23 23:57:37,275 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-23 23:57:37,454 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-03-23 23:57:37,802 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-03-23 23:57:37,802 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-03-23 23:57:38,305 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jaywang/dfs/namesecondary/in_use.lock acquired by nodename 33209@jays-MacBook-Pro-2.local
2015-03-23 23:57:38,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2015-03-23 23:57:38,430 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-03-23 23:57:38,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-03-23 23:57:38,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-03-23 23:57:38,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2015-03-23 23:57:38,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2015 Mar 23 23:57:38
2015-03-23 23:57:38,478 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-03-23 23:57:38,478 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-23 23:57:38,481 INFO org.apache.hadoop.util.GSet: 2.0% max memory 987.5 MB = 19.8 MB
2015-03-23 23:57:38,481 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-03-23 23:57:38,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-03-23 23:57:38,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-03-23 23:57:38,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-03-23 23:57:38,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-03-23 23:57:38,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-03-23 23:57:38,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-03-23 23:57:38,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-03-23 23:57:38,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-03-23 23:57:38,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-03-23 23:57:38,498 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jaywang (auth:SIMPLE)
2015-03-23 23:57:38,498 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-03-23 23:57:38,498 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-03-23 23:57:38,498 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-03-23 23:57:38,501 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-03-23 23:57:38,707 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-03-23 23:57:38,707 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-23 23:57:38,707 INFO org.apache.hadoop.util.GSet: 1.0% max memory 987.5 MB = 9.9 MB
2015-03-23 23:57:38,707 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2015-03-23 23:57:38,708 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-03-23 23:57:38,717 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-03-23 23:57:38,717 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2015-03-23 23:57:38,717 INFO org.apache.hadoop.util.GSet: 0.25% max memory 987.5 MB = 2.5 MB
2015-03-23 23:57:38,717 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2015-03-23 23:57:38,718 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-03-23 23:57:38,718 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-03-23 23:57:38,718 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-03-23 23:57:38,721 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2015-03-23 23:57:38,721 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2015-03-23 23:57:38,721 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2015-03-23 23:57:38,734 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2015-03-23 23:57:38,785 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-03-23 23:57:38,790 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2015-03-23 23:57:38,802 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-03-23 23:57:38,804 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-03-23 23:57:38,805 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-03-23 23:57:38,805 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-03-23 23:57:38,839 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2015-03-23 23:57:38,840 INFO org.mortbay.log: jetty-6.1.26
2015-03-23 23:57:39,085 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2015-03-23 23:57:39,085 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-03-23 23:57:39,086 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-03-23 23:57:39,086 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-03-23 23:58:39,398 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-03-23 23:58:39,906 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=3032&storageInfo=-60:1910406943:0:CID-ee3d8ff1-8579-49a9-a16f-57ba16abf638
2015-03-23 23:58:39,971 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2015-03-23 23:58:40,410 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 1000.00 KB/s
2015-03-23 23:58:40,410 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000003032 size 9640 bytes.
2015-03-23 23:58:40,419 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=3033&endTxId=3034&storageInfo=-60:1910406943:0:CID-ee3d8ff1-8579-49a9-a16f-57ba16abf638
2015-03-23 23:58:40,423 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2015-03-23 23:58:40,423 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003033-0000000000000003034_0000001427169520418 size 0 bytes.
2015-03-23 23:58:40,460 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 97 INodes.
2015-03-23 23:58:40,506 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-03-23 23:58:40,506 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 3032 from /tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000003032
2015-03-23 23:58:40,507 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-03-23 23:58:40,512 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-03-23 23:58:40,526 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000003033-0000000000000003034 expecting start txid #3033
2015-03-23 23:58:40,526 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000003033-0000000000000003034
2015-03-23 23:58:40,546 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jaywang/dfs/namesecondary/current/edits_0000000000000003033-0000000000000003034 of size 42 edits # 2 loaded in 0 seconds
2015-03-23 23:58:40,595 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3032
2015-03-23 23:58:40,595 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2015-03-23 23:58:40,595 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jaywang/dfs/namesecondary/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2015-03-23 23:58:40,703 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3034 to namenode at http://localhost:50070 in 0.098 seconds
2015-03-23 23:58:40,704 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 9640
2015-03-24 00:11:53,823 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-03-24 00:11:53,825 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jays-MacBook-Pro-2.local/10.190.38.245
************************************************************/
