Benchmark 2 - MR workload
running overweight_zips_mr.sql script in /queries
setting up tables

Logging initialized using configuration in file:/Users/jaywang/Desktop/Tez/hive-0.13.1/conf/hive-log4j.properties
2015-04-09 13:01:03.225 java[25616:322710] Unable to load realm info from SCDynamicStore
OK
Time taken: 1.842 seconds
OK
Time taken: 0.192 seconds
Copying data from file:/Users/jaywang/Desktop/data/input_data/weight_data.csv
Copying file: file:/Users/jaywang/Desktop/data/input_data/weight_data.csv
Loading data to table default.weight
rmr: DEPRECATED: Please use 'rm -r' instead.
Deleted hdfs://localhost:9000/Users/jaywang/Desktop/data/hive_tables/weight
Table default.weight stats: [numFiles=0, numRows=0, totalSize=0, rawDataSize=0]
OK
Time taken: 0.552 seconds
OK
Time taken: 0.103 seconds
OK
Time taken: 0.031 seconds
Copying data from file:/Users/jaywang/Desktop/data/input_data/population_density_zip.csv
Copying file: file:/Users/jaywang/Desktop/data/input_data/population_density_zip.csv
Loading data to table default.population_density_zip
rmr: DEPRECATED: Please use 'rm -r' instead.
Deleted hdfs://localhost:9000/Users/jaywang/Desktop/data/hive_tables/population_density_zip
Table default.population_density_zip stats: [numFiles=0, numRows=0, totalSize=0, rawDataSize=0]
OK
Time taken: 0.237 seconds
OK
Time taken: 0.085 seconds
OK
Time taken: 0.032 seconds
Total jobs = 1
Launching Job 1 out of 1


Status: Running (application id: application_1428597279593_0007)

Map 1: -/-	Map 2: -/-	Reducer 3: 0/1	
Map 1: 0/1	Map 2: 0/1	Reducer 3: 0/1	
Map 1: 0/1	Map 2: 0/1	Reducer 3: 0/1	
Map 1: 1/1	Map 2: 0/1	Reducer 3: 0/1	
Map 1: 1/1	Map 2: 1/1	Reducer 3: 0/1	
Map 1: 1/1	Map 2: 1/1	Reducer 3: 1/1	
Status: Finished successfully
Loading data to table default.top_overweight_zips
rmr: DEPRECATED: Please use 'rm -r' instead.
Deleted hdfs://localhost:9000/Users/jaywang/Desktop/data/hive_tables/top_overweight_zips
Table default.top_overweight_zips stats: [numFiles=0, numRows=100, totalSize=0, rawDataSize=2159]
OK
Time taken: 16.46 seconds
OK
Time taken: 0.108 seconds
OK
Time taken: 0.033 seconds
Total jobs = 1
Launching Job 1 out of 1


Status: Running (application id: application_1428597279593_0007)

Map 1: -/-	Map 2: -/-	Reducer 3: 0/1	
Map 1: 0/1	Map 2: 0/1	Reducer 3: 0/1	
Map 1: 1/1	Map 2: 0/1	Reducer 3: 0/1	
Map 1: 1/1	Map 2: 1/1	Reducer 3: 0/1	
Map 1: 1/1	Map 2: 1/1	Reducer 3: 1/1	
Status: Finished successfully
Loading data to table default.least_overweight_zips
rmr: DEPRECATED: Please use 'rm -r' instead.
Deleted hdfs://localhost:9000/Users/jaywang/Desktop/data/hive_tables/least_overweight_zips
Table default.least_overweight_zips stats: [numFiles=0, numRows=100, totalSize=0, rawDataSize=2187]
OK
Time taken: 2.13 seconds
-- running ---

Logging initialized using configuration in file:/Users/jaywang/Desktop/Tez/hive-0.13.1/conf/hive-log4j.properties
2015-04-09 13:01:32.912 java[25893:324168] Unable to load realm info from SCDynamicStore
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428597279593_0008, Tracking URL = http://jays-MacBook-Pro-2.local:8088/proxy/application_1428597279593_0008/
Kill Command = /Users/jaywang/Desktop/Tez/hadoop-2.6.0/bin/hadoop job  -kill job_1428597279593_0008
Hadoop job information for Stage-1: number of mappers: 0; number of reducers: 0
2015-04-09 13:01:49,183 Stage-1 map = 0%,  reduce = 0%
2015-04-09 13:01:55,421 Stage-1 map = 100%,  reduce = 0%
2015-04-09 13:02:01,654 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_1428597279593_0008
MapReduce Jobs Launched: 
Job 0:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
Average population density per zip code: 	1254.6468685961365
Time taken: 23.528 seconds, Fetched: 1 row(s)
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428597279593_0009, Tracking URL = http://jays-MacBook-Pro-2.local:8088/proxy/application_1428597279593_0009/
Kill Command = /Users/jaywang/Desktop/Tez/hadoop-2.6.0/bin/hadoop job  -kill job_1428597279593_0009
Hadoop job information for Stage-1: number of mappers: 0; number of reducers: 0
2015-04-09 13:02:12,503 Stage-1 map = 0%,  reduce = 0%
2015-04-09 13:02:19,778 Stage-1 map = 100%,  reduce = 0%
2015-04-09 13:02:24,946 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_1428597279593_0009
MapReduce Jobs Launched: 
Job 0:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
Average population density per zip code (top overweight): 	953.66536454547
Time taken: 23.181 seconds, Fetched: 1 row(s)
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428597279593_0010, Tracking URL = http://jays-MacBook-Pro-2.local:8088/proxy/application_1428597279593_0010/
Kill Command = /Users/jaywang/Desktop/Tez/hadoop-2.6.0/bin/hadoop job  -kill job_1428597279593_0010
Hadoop job information for Stage-1: number of mappers: 0; number of reducers: 0
2015-04-09 13:02:36,356 Stage-1 map = 0%,  reduce = 0%
2015-04-09 13:02:43,623 Stage-1 map = 100%,  reduce = 0%
2015-04-09 13:02:49,827 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_1428597279593_0010
MapReduce Jobs Launched: 
Job 0:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
Average population density per zip code (least overweight): 	1454.0622953780796
Time taken: 24.864 seconds, Fetched: 1 row(s)
Benchmark 2 - MR complete